---
title: 'Introduction to Tidyverse for Data Science'
author: "Jason Liu and Clayton Halim"
date: "9/5/2017"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

# The efficient data scientist.

I'm going to try to keep the buzzword density low here.

Data science, oversimplified, can be though of as two classes of work, **Algorithms** and **Analytics**. While analytics may not be doing algorithm design or complex modeling, those who are implementing these algorithms on real data often find themselves to analyzing data. They need to understand the biases their models have and confirm that the data is approporiate for the model.

## What is the difference?

From my own perspective...

**Analytics:** Studying the business's data and making recommendations, understanding experiments to improve operations and product. This type of data science is about transforming businesses using insights. 

**Algorithms:** Using machine learning and statistics to build tools. Here, the service or model is the product.

Even within the realm of algorithms and machine learning, to make best models, we need to understand the requirements of the data for models to succeed and to confirm these models. For example, take the Anscombe's Quartet.

It turns out that the quantiles, correlation, r squared of a linear model on these data are all the same. This is a common pitfall that occur when we try modeling without... practising safe statistics.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
data("anscombe")
anscombe %>% 
  gather(x, xval, x1:x4) %>%
  gather(y, yval, y1:y4) %>% 
  mutate(x= stringr::str_sub(x, 2,2)) %>% 
  mutate(y= stringr::str_sub(y, 2,2)) %>% 
  filter(x == y) %>% 
  select(type=x, x=xval, y=yval) %>% 
  ggplot(aes(x=x, y=y)) + geom_point() + geom_smooth(method=lm, se=FALSE, fullrange=TRUE) + facet_wrap(~type)
```

# The Standard. Tidy Data.

>Happy families are all alike; every unhappy family is unhappy in its own way.

Tidy data is a standard way of mapping the meaning of a dataset to its structure. A dataset is messy or tidy depending on how rows, columns and tables are matched up with observations, variables and types. In tidy data:

1. Each variable forms a column.
2. Each observation forms a row.
3. Each type of observational unit forms a table.
4. A single observational unit is stored in multiple tables.
 
Tidy data makes it easy for an analyst or a computer to extract needed variables because it provides a standard way of structuring a dataset

The five most common problems with messy datasets, along with their remedies:

1. Column headers are values, not variable names.
2. Multiple variables are stored in one column.
3. Variables are stored in both rows and columns.
4. Multiple types of observational units are stored in the same table.  

The text above came from http://www.jstatsoft.org/v59/i10/paper, the original tidy data paper. 

The value will become more and more apparent when doing transformations and visualizations on datasets that are more complex.

## tidyr::gather

```{r}
table4b
```

Notice that the in this table the column names are the years and the variable that represents the values are unclear. We can use the `tidyr::gather` command to reshape and tidy the data.

```{r}
table4b %>% 
  gather(year, population, 2:3)
```

## tidyr::spread

The opposite of gather is spread, which is often helpful for human readability.

```{r}
table2
```

Here we just need to pass in the column name that will be converted into rows and the value.

```{r}
table2 %>% 
  spread(type, count)
```

This would be usefull if we want to compute a new value such as `rate=cases/population`.

## tidyr::unite, tidyr::seperate

There are also functions called `unite` and `seperate` that I encourage you to learn these on your own. Try `??seperate` in the command line. These will split one column into many columns and vise versa. 

These functions are useful for cases when one column contains many variables, for example when a column has values such as `male_treatmenta` we might want to seperate this value on `_` and transform into a `gender` and `treatment_type` columns. 

# Data Transformation

Data transformation is a process useful for converting one data format to another. You will later see things like filtering data based on the required conditions, creating new columns, etc.

Source: [dplyr tutorial](http://genomicsclass.github.io/book/pages/dplyr_tutorial.html)

## What is dplyr?

dplyr is a powerful R-package to transform and summarize tabular data with rows and columns.

## Why is it useful?

The package contains a set of functions (or “verbs”) that perform common data manipulation operations such as filtering for rows, selecting specific columns, re-ordering rows, adding new columns and summarizing data.

In addition, dplyr contains a useful function to perform another common task which is the “split-apply-combine” concept. We will discuss that in a little bit.

## Important dplyr verbs to remember

- `select()`: select columns
- `filter()`:	filter rows
- `arrange()`:	re-order or arrange rows
- `mutate()`:	create new columns
- `summarise()`:	summarise values
- `group_by()`:	allows for group operations in the “split-apply-combine” concept


## Dataset: Cars (mpg)

Quick look at the first 5 entires in the data
```{R, message = FALSE}
head(mpg)
```

#### Selecting columns using `select()`

You can select certain columns by specifying the dataset and the columns you want to include afterwards
```{R}
car_models <- select(mpg, manufacturer, model, year)
head(car_models)
```
You can select all but a certain column by using the `-` (subtraction) operation, aka negative indexing.
```{R}
head(select(car_models, -year))  
```

You can also select a range of columns using `:`

```{R}
head(select(mpg, manufacturer:year))
```

Some additional options to select columns based on a specific criteria include

- `ends_with()` = Select columns that end with a character string
- `contains()` = Select columns that contain a character string
- `matches()` = Select columns that match a regular expression
- `one_of()` = Select columns names that are from a group of names

### Selecting rows using `filter()`

`filter()` works by passing in the dataset and giving the columns of interest a condition to pass.

For example, all cars made by Audi in 1999:

```{R}
filter(mpg, year == 1999, manufacturer == "audi")
```

## Pipe operator: `%>%`

Before we go any futher, let’s introduce the pipe operator: `%>%`. dplyr imports this operator from another package (magrittr). This operator allows you to pipe the output from one function to the input of another function. Instead of nesting functions (reading from the inside to the outside), the idea of of piping is to read the functions from left to right.

If I wanted to see select car models that are made after 2005, have more than 20 city miles per gallon, and see only the first 3 entries, I could do it like:

```{R}
head(select(filter(mpg, year < 2005, cty > 20), model), 3)
```
As you can see this is really hard to read, but with pipes we can get the same result in a cleaner fashion.

```{R}
mpg %>%
  filter(year < 2005, cty > 20) %>%
  select(model) %>%
  head(3)
```

### Reorder rows with `arrange()`

You can sort your rows in ascending order by any combination of columns using arrange.

```{R}
mpg %>%
  arrange(displ) %>%
  head
```
Use `desc()` to get descending order.

```{R}
mpg %>%
  arrange(desc(displ), year) %>%
  head
```

### Create new columns using mutate()

The `mutate()` function will add new columns to the data frame. We can create a new column `apg`, that is _average miles per galon_.

```{R}
mpg %>%
  mutate(apg = (cty + hwy) / 2) %>%
  select(manufacturer, model, year, cty, hwy, apg) %>%
  head
```
You can add more than one column by separating the variables by comma in the function parameters.

###Create summaries of the data frame using `summarise()`

The `summarise()` function will create summary statistics for a given column in the data frame such as finding the mean. For example, to compute the average city miles per gallon and average highway miles per gallon, we apply the `mean()` function to these columns.

```{R}
mpg %>%
  summarise(cty_avg = mean(cty), hwy_avg = mean(hwy))
```
Some other statistics you may want to apply are:

- `sd()` : standard deviation of column
- `min()`: min value in column
- `max()`: max value in column
- `median()`: median value in column
- `sum()`: sum of all values in column
- `n()`: number of entries in column
- `n_distinct()`: number of unique entries in column
- `first()`: returns first value in column
- `last()`: returns last value in column

### Group operations using `group_by()`

The group_by() verb is an important function in dplyr. As we mentioned before it’s related to concept of “split-apply-combine”. We literally want to split the data frame by some variable (e.g. manufacturer), apply a function to the individual data frames and then combine the output.

Let’s do that: split the mpg data frame by the manufactuer, then ask for the same summary statistics as above. We expect a set of summary statistics for each manufacturer.

```{R}
mpg %>%
  group_by(manufacturer) %>%
  summarise(avg_year = mean(year), avg_cyl = mean(cyl), 
            avg_cty = mean(cty), avg_hwy = mean(hwy))
```

# Data Visualization

R has several libraries for making graphs, but ggplot2 is one of the most elegant and most versatile. ggplot2 implements the grammar of graphics, a coherent system for describing and building graphs.

If you’d like to learn more about the theoretical underpinnings of ggplot2 before you start, I’d recommend reading “The Layered Grammar of Graphics”, http://vita.had.co.nz/papers/layered-grammar.pdf. 

```{r}
mpg
```

Among the variables in mpg are:

1. `displ`, a car’s engine size, in litres.

2. `hwy`, a car’s fuel efficiency on the highway, in miles per gallon (mpg). A car with a low fuel efficiency consumes more fuel than a car with a high fuel efficiency when they travel the same distance.

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))
```

Here we see a negative correlation between engine size to fuel efficiency.

## Aestetics.

By looking at our dataset

```{r}
head(mpg)
```

We see many other variables we may want to encode into your visualization.

For example, the class of the car

```{r}
ggplot(data = mpg, 
       mapping=aes(x = displ, y = hwy, color=class)) + 
  geom_point()
```

The colors reveal that many of the unusual points are two-seater cars. These cars don’t seem like hybrids, and are, in fact, sports cars! Sports cars have large engines like SUVs and pickup trucks, but small bodies like midsize and compact cars, which improves their gas mileage.

```{r}
ggplot(data = mpg, 
       mapping=aes(x = displ, y = hwy, shape=class)) + 
  geom_point()
```

Check out the docs and see what other visuals we can encode using the `mapping=...` variables.  

## Facets

One way to add additional variables is with aesthetics. Another way, particularly useful for categorical variables, is to split your plot into facets, subplots that each display one subset of the data. Note that this only works if you have Tidy data.

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_wrap(~ class, nrow = 2)
```

## Geoms

A **geom** is the geometrical object that a plot uses to represent data. People often describe plots by the type of geom that the plot uses. For example, bar charts use bar geoms, line charts use line geoms, boxplots use boxplot geoms, and so on. 

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))
```

```{r}
ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy))
```

```{r}
ggplot(data = mpg, mapping=aes(x = displ, y = hwy)) + 
  geom_point() +
  geom_smooth()
```

We can do the same for having categorical plots.

```{r}
mpg %>% 
  group_by(class) %>% 
  summarise(mean_hwy=mean(hwy)) %>%
  ggplot(aes(x=class, y=mean_hwy)) +
    geom_col() + 
    coord_flip()
```

## More fun stuff.

ggplot2 is a extremely expressive and powerful plotting library. If you want a deeper dive into this library, you can look into this [R Tutorial](http://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html) from Harard. You can also look at [Top 50 ggplot2 visualizations](http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html) for some insperation for new plot ideas!